{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (LeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.tensor.nnet import conv\n",
    "\n",
    "import numpy\n",
    "\n",
    "rng = numpy.random.RandomState(23455)\n",
    "\n",
    "# instantiate 4D tensor for input\n",
    "input = T.tensor4(name='input')\n",
    "\n",
    "# initialize shared variable for weights.\n",
    "w_shp = (2, 3, 9, 9)\n",
    "w_bound = numpy.sqrt(3 * 9 * 9)\n",
    "W = theano.shared( numpy.asarray(\n",
    "            rng.uniform(\n",
    "                low=-1.0 / w_bound,\n",
    "                high=1.0 / w_bound,\n",
    "                size=w_shp),\n",
    "            dtype=input.dtype), name ='W')\n",
    "\n",
    "# initialize shared variable for bias (1D tensor) with random values\n",
    "# IMPORTANT: biases are usually initialized to zero. However in this\n",
    "# particular application, we simply apply the convolutional layer to\n",
    "# an image without learning the parameters. We therefore initialize\n",
    "# them to random values to \"simulate\" learning.\n",
    "b_shp = (2,)\n",
    "b = theano.shared(numpy.asarray(\n",
    "            rng.uniform(low=-.5, high=.5, size=b_shp),\n",
    "            dtype=input.dtype), name ='b')\n",
    "\n",
    "# build symbolic expression that computes the convolution of input with filters in w\n",
    "conv_out = conv.conv2d(input, W)\n",
    "\n",
    "# build symbolic expression to add bias and apply activation function, i.e. produce neural net layer output\n",
    "# A few words on ``dimshuffle`` :\n",
    "#   ``dimshuffle`` is a powerful tool in reshaping a tensor;\n",
    "#   what it allows you to do is to shuffle dimension around\n",
    "#   but also to insert new ones along which the tensor will be\n",
    "#   broadcastable;\n",
    "#   dimshuffle('x', 2, 'x', 0, 1)\n",
    "#   This will work on 3d tensors with no broadcastable\n",
    "#   dimensions. The first dimension will be broadcastable,\n",
    "#   then we will have the third dimension of the input tensor as\n",
    "#   the second of the resulting tensor, etc. If the tensor has\n",
    "#   shape (20, 30, 40), the resulting tensor will have dimensions\n",
    "#   (1, 40, 1, 20, 30). (AxBxC tensor is mapped to 1xCx1xAxB tensor)\n",
    "#   More examples:\n",
    "#    dimshuffle('x') -> make a 0d (scalar) into a 1d vector\n",
    "#    dimshuffle(0, 1) -> identity\n",
    "#    dimshuffle(1, 0) -> inverts the first and second dimensions\n",
    "#    dimshuffle('x', 0) -> make a row out of a 1d vector (N to 1xN)\n",
    "#    dimshuffle(0, 'x') -> make a column out of a 1d vector (N to Nx1)\n",
    "#    dimshuffle(2, 0, 1) -> AxBxC to CxAxB\n",
    "#    dimshuffle(0, 'x', 1) -> AxB to Ax1xB\n",
    "#    dimshuffle(1, 'x', 0) -> AxB to Bx1xA\n",
    "output = T.nnet.sigmoid(conv_out + b.dimshuffle('x', 0, 'x', 'x'))\n",
    "\n",
    "# create theano function to compute filtered images\n",
    "f = theano.function([input], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pylab\n",
    "from PIL import Image\n",
    "\n",
    "# open random image of dimensions 639x516\n",
    "img = Image.open(open('../doc/images/3wolfmoon.jpg'))\n",
    "# dimensions are (height, width, channel)\n",
    "img = numpy.asarray(img, dtype='float64') / 256.\n",
    "\n",
    "# put image in 4D tensor of shape (1, 3, height, width)\n",
    "img_ = img.transpose(2, 0, 1).reshape(1, 3, 639, 516)\n",
    "filtered_img = f(img_)\n",
    "\n",
    "# plot original image and first and second components of output\n",
    "pylab.subplot(1, 3, 1); pylab.axis('off'); pylab.imshow(img)\n",
    "pylab.gray();\n",
    "# recall that the convOp output (filtered image) is actually a \"minibatch\",\n",
    "# of size 1 here, so we take index 0 in the first dimension:\n",
    "pylab.subplot(1, 3, 2); pylab.axis('off'); pylab.imshow(filtered_img[0, 0, :, :])\n",
    "pylab.subplot(1, 3, 3); pylab.axis('off'); pylab.imshow(filtered_img[0, 1, :, :])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.0859375 ,  0.0546875 ,  0.10546875],\n",
       "        [ 0.109375  ,  0.0859375 ,  0.125     ],\n",
       "        [ 0.08984375,  0.0859375 ,  0.109375  ],\n",
       "        ..., \n",
       "        [ 0.07421875,  0.06640625,  0.0703125 ],\n",
       "        [ 0.05859375,  0.0625    ,  0.078125  ],\n",
       "        [ 0.0703125 ,  0.08203125,  0.1015625 ]],\n",
       "\n",
       "       [[ 0.09375   ,  0.06640625,  0.09765625],\n",
       "        [ 0.10546875,  0.0859375 ,  0.109375  ],\n",
       "        [ 0.0859375 ,  0.0859375 ,  0.09375   ],\n",
       "        ..., \n",
       "        [ 0.05859375,  0.04296875,  0.046875  ],\n",
       "        [ 0.05859375,  0.0546875 ,  0.07421875],\n",
       "        [ 0.06640625,  0.0703125 ,  0.08984375]],\n",
       "\n",
       "       [[ 0.109375  ,  0.0859375 ,  0.09375   ],\n",
       "        [ 0.109375  ,  0.09375   ,  0.09765625],\n",
       "        [ 0.0859375 ,  0.0859375 ,  0.0859375 ],\n",
       "        ..., \n",
       "        [ 0.0703125 ,  0.046875  ,  0.0546875 ],\n",
       "        [ 0.09375   ,  0.07421875,  0.09765625],\n",
       "        [ 0.06640625,  0.0625    ,  0.0859375 ]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.06640625,  0.07421875,  0.03125   ],\n",
       "        [ 0.08203125,  0.09375   ,  0.05859375],\n",
       "        [ 0.05078125,  0.08203125,  0.0390625 ],\n",
       "        ..., \n",
       "        [ 0.06640625,  0.0625    ,  0.0859375 ],\n",
       "        [ 0.078125  ,  0.07421875,  0.09765625],\n",
       "        [ 0.0859375 ,  0.08203125,  0.10546875]],\n",
       "\n",
       "       [[ 0.046875  ,  0.05078125,  0.01953125],\n",
       "        [ 0.05078125,  0.07421875,  0.03515625],\n",
       "        [ 0.0390625 ,  0.06640625,  0.03515625],\n",
       "        ..., \n",
       "        [ 0.05859375,  0.0625    ,  0.0703125 ],\n",
       "        [ 0.06640625,  0.0703125 ,  0.078125  ],\n",
       "        [ 0.0703125 ,  0.07421875,  0.08203125]],\n",
       "\n",
       "       [[ 0.046875  ,  0.05859375,  0.0234375 ],\n",
       "        [ 0.04296875,  0.06640625,  0.02734375],\n",
       "        [ 0.0234375 ,  0.0625    ,  0.02734375],\n",
       "        ..., \n",
       "        [ 0.0703125 ,  0.078125  ,  0.06640625],\n",
       "        [ 0.06640625,  0.07421875,  0.0625    ],\n",
       "        [ 0.05078125,  0.05859375,  0.046875  ]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
